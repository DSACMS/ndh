# National Health Directory Approach and Strategy

## Strategy

### Strategic Landscape

* Health IT is difficult because of a "tangles of arbitrarily added complexity".
* The problems in Health IT tend to be:
  * Data Diversity rather than Data Scale.
  * Complex Clinical Semantics resolved to arbitrary syntaxes results in "faxonomys". Taxonomies that are clinical, but not clinically valid.
  * An Ontology is a structuring of data that leads to insights. A faxonomy is a structuring of data, where the structure generally interferes with the ability to gain insight.
  * Generally, everything clinical in a medical billing context has all of the downsides of banking data and clinical data, the upsides of neither, and new problems that arise only when they are together.
  * All data that is generated by clinical care that is paid for by an insurance company is "medical billing data". Not just the medical claims themselves, but the EHR records, MRI records and laboratory tests.
  * The only good starting assumption is that *nothing* is what it says on the tin.
  * In many cases the "Faxonomies" are closely guarded intellectual property assets (CPT codes most dramatically), and represent low-key "framing conflicts", between CMS/HHS/CDC and the AMA/AHA/NCPDP/WHO/APA and others.
* It is not true that you have to understand all of it to understand any of it.
* But it is true that you have to have a general understanding of most of it to start understanding some of it.
* AI changes everything, including Health IT.
* It is not clear -how- AI changes any part of what we are doing.
* We have a very narrow opportunity window where everything is algined to achieve a good NPD. We must go fast.
* We have limited personelle resources, and we will aquire more personelle resources in an unpredictable trickle
* A trickle of resources, and the delta between Health IT expertise and developer expertise
* Goodhart's Law applies to everything we do. Altering the provider enumeration approach will cause unintended consequences, and we should be careful when a change in technology approach might implicity be a policy change.
* Despite this, we will need to change multiple fundementally techo-policy issues. Which we will do carefully.

### Foundational Technology Strategy

* No Proprietary Lock-in: Avoid proprietary technologies, platforms, or services.
* Long-Term Sustainability: Plan for a 50-year timeline using mature, widely adopted technologies. Plan in accordance with the [Lindy Effect](https://en.m.wikipedia.org/wiki/Lindy_effect)
* Preference for Old and Stable Tools: Prioritize tools with 10+ years of proven utility.
* If there's smoke, go and smell it yourself. a Rickover Principle which in data translates to "report extensively on your data, so that you can know when and how it changes". Practically, this means building reporting capability early
* Use the honeycomb approach. Create small software modules that have consistent frameworks to leverage AI (worker bees) to implement complexity only 'within' each honeycomb.

### Honeycomb approach to Health IT complexity

* Health IT complexity tends to be in combinatorics of small weird problems and requirements creating a tangled and unmanaged whole.
* This is exactly the type of complexity that AI coding tools currently struggle with.
* This makes "Detail denial" an especially dangerous mistake.
* To solve Health IT problems each type of problem needs to be well framed and boxed in, so that an AI can successfully ignore the complexity of the larger system while it works on a single part of the whole.
* Keep the abstraction layers as thin as possible. All abstractions are leaky. But thin ones keep the underlying complexity close to the surface. To put this another way: automations should tend to make coding easier but never to actually 'avoid' coding.

### Data Processing and Integration

* Universal Execution Contexts: Ensure support in Python, Jupyter Notebooks, Unix CLI, and SAS. Data pipeline options that do not support all of these and all potential future data contexts are non-starters.
* SQL-Centric Processing: Use plain SQL for transformations, interleaved with Python.
  * When it is not possible to simply hand code the SQL steps a 'compile to sql' approach should be taken
  * There are numerous cases where a data transformation must be in R, Pandas or SAS data steps. But this should never be based on mere programmer preference, and the reasons for the exceptions should be clearly documented.

### Scalability and Accessibility

* Dual Schema Design: Separate public and private schemas.
* Downloadable Data: Support bulk access with moderate API load.

### Compatibility Requirements

* NPPES Backward Compatibility:
  * Reproduce NPPES flat files
  * Maintain entity types, Medicare codes, and NUCC taxonomy
* Claims & Regulatory Continuity:
  * Medicaid ACOs, QHPs, FQHCs, and legacy systems

### FHIR Compliance

* Strict Schema Alignment: Must pass validation against FHIR schemas.
* Correct Resource Use: Use FHIR elements per spec (e.g., PractitionerRole).

### Data Quality and Feedback

* Validate When Possible: Fully validate or track confidence levels.
* User Feedback Channels:
  * Patient-facing UX for data accuracy
  * Token-limited write-back API for structured corrections

### Decision-Making Heuristics

* Reliable > Experimental: Use proven tools.
* Ensure backward/future compatibility.

## Engineering Process Philosophy

### Git-Based Collaboration

* Use Git/GitHub workflows.
* Clean, small PRs preferred, but large PRs accepted when necessary.
  * Convert the biggest pull requests into separate modules. Honeycomb approach.
* Emphasize clarity and forward momentum.

### Test-Driven Expectations

* Expectations Before APIs: Define tests before implementation.
* Test-Driven Data Models: Built alongside ETLs with validations.
* ETL Resilience by Design:
  * Validate assumptions
  * Break early and loudly on errors

### Anti-Fragile Infrastructure

* Fail Loudly, Recover Quickly: Small, fragile components improve overall system robustness.
* Continuous Feedback Loops: Tests and checks detect degradations early.
  * Leverage lots of different kinds of tests, generally preferring higher level tests that will detect between system failures
  * Specifically leverage data expectation tests to avoid pipeline technical debt
  * Data expectations should make us aware of healthcare ecosystem changes as much as data etc errors. I.e. if all of the pediatricians are suddenly men. This could mean a dramatic change in the healthcare system or a broken import script.

### Legacy Respect: The Joel on Software Principle

* No Clean Slate Rebuilds: Avoid rewrites; understand existing code first.
* Inherited Code is Knowledge: Features represent hard-earned lessons.
* Respect Before Refactor: Prior design is valid until proven otherwise.
* Avoid Reinventing Mistakes: Rewrites risk losing key insights.
* Evolve, Don't Replace: Improve incrementally.

## FHIR and NDH Implementation Summary

### FHIR Standards and Schema Validation

* Validate against:
  * FHIR Core
  * US Core (minimum required)
  * FAST NDH Profiles
* Understand profile hierarchy: FHIR Core -> US Core -> NDH
* Key HL7 profile tabs:
  * Differential: What's changed
  * Snapshot: Full schema view
  * Key Elements: Essential fields

### Terminologies & Functional Coding

* Use SNOMED codes in PractitionerRole for services
* Continue using NUCC taxonomy for classifications

### Account Access

* Ensure team members have:
  * VSAC (Value Set Authority Center) access
  * Active UMLS credentials

### Direct Address Representation

* List direct addresses in:
  * telecom field
  * endpoint resource

### Available Time & Scheduling

* Use availableTime in PractitionerRole
* Link availableTime to specific Location
* Investigate dynamic scheduling endpoint integration

### Location vs Organization Modeling

* Use Location for places of care
* Strategy:
  * Deduplicate locations across organizations
  * Link PractitionerRoles via Locations to simplify API

### Practitioner Names & Status

* PractitionerRole requires full-text name
* NDH requires all records active
* Consider inactive NPIs for completeness

### Telecom Enhancements

* telecom fields can have time-bound validity

### Location Geocoding

* Not currently supported
* Use extension for geocoding in this version

### Verification Object

* verificationResult = whole-resource confidence
* No sub-element confidence standard exists
* Plan custom extension for sub-element confidence

### PractitionerRole & Licensing Strategy

* Licensing is state-specific
* Modeling strategy:
  * Create Location per state
  * Link PractitionerRole to correct state Location
  * Assign appropriate taxonomies

### Required Extensions

* Geolocation support (extension)
* Sub-element confidence (extension)
* Aligned program participation tracking
